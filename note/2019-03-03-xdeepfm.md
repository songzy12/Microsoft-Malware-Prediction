又运行了一次。

LB: 0.690

blend with lgb (0.693), then blend with the best kernel (0.697): 0.697

```
Loading Train and Test Data.

  activation=['relu', 'relu', 'relu']
  batch_norm_decay=0.9
  batch_size=1024
  cross_activation=identity
  cross_layer_sizes=[128, 128, 128]
  epoch=1
  feature_nums=81
  hash_ids=200000
  hidden_size=[1024, 128]
  init_method=uniform
  init_value=0.1
  k=8
  kfold=5
  learning_rate=0.001
  metric=auc
  model=xdeepfm
  norm=True
  num_display_steps=1000
  num_eval_steps=1000
  optimizer=adam
Number: 1784296
Number: 1784296
Number: 1784296
Number: 1784296
Number: 1784299
Fold 0
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.619593 gN 0.26, Sat Mar  2 02:20:45 2019
# Epcho-time 1406.16s Eval AUC 0.722909. Best AUC 0.722909.
  epoch 0 step 2000 lr 0.001 logloss 0.606306 gN 0.22, Sat Mar  2 02:46:07 2019
# Epcho-time 2928.54s Eval AUC 0.729902. Best AUC 0.729902.
  epoch 0 step 3000 lr 0.001 logloss 0.602520 gN 0.20, Sat Mar  2 03:11:36 2019
# Epcho-time 4457.23s Eval AUC 0.733077. Best AUC 0.733077.
  epoch 0 step 4000 lr 0.001 logloss 0.599634 gN 0.19, Sat Mar  2 03:37:05 2019
# Epcho-time 5986.16s Eval AUC 0.735650. Best AUC 0.735650.
  epoch 0 step 5000 lr 0.001 logloss 0.597650 gN 0.18, Sat Mar  2 04:02:30 2019
# Epcho-time 7511.74s Eval AUC 0.737109. Best AUC 0.737109.
  epoch 0 step 6000 lr 0.001 logloss 0.597180 gN 0.18, Sat Mar  2 04:27:56 2019
# Epcho-time 9037.08s Eval AUC 0.738728. Best AUC 0.738728.
# Epcho-time 10523.59s Eval AUC 0.738606. Best AUC 0.738728.
# Epcho-time 10624.85s Eval AUC 0.738731. Best AUC 0.738731.
Training Done! Inference...
Fold 1
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.620647 gN 0.28, Sat Mar  2 07:19:11 2019
# Epcho-time 1478.08s Eval AUC 0.723226. Best AUC 0.723226.
  epoch 0 step 2000 lr 0.001 logloss 0.606442 gN 0.22, Sat Mar  2 07:45:30 2019
# Epcho-time 3057.00s Eval AUC 0.730171. Best AUC 0.730171.
  epoch 0 step 3000 lr 0.001 logloss 0.602475 gN 0.21, Sat Mar  2 08:11:49 2019
# Epcho-time 4636.56s Eval AUC 0.734191. Best AUC 0.734191.
  epoch 0 step 4000 lr 0.001 logloss 0.599729 gN 0.20, Sat Mar  2 08:38:07 2019
# Epcho-time 6214.43s Eval AUC 0.735926. Best AUC 0.735926.
  epoch 0 step 5000 lr 0.001 logloss 0.597854 gN 0.19, Sat Mar  2 09:04:21 2019
# Epcho-time 7787.68s Eval AUC 0.738247. Best AUC 0.738247.
  epoch 0 step 6000 lr 0.001 logloss 0.597301 gN 0.18, Sat Mar  2 09:30:38 2019
# Epcho-time 9365.10s Eval AUC 0.739485. Best AUC 0.739485.
# Epcho-time 10896.11s Eval AUC 0.739580. Best AUC 0.739580.
# Epcho-time 11001.66s Eval AUC 0.739577. Best AUC 0.739580.
Training Done! Inference...
Fold 2
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.621783 gN 0.28, Sat Mar  2 12:47:03 2019
# Epcho-time 1492.06s Eval AUC 0.720230. Best AUC 0.720230.
  epoch 0 step 2000 lr 0.001 logloss 0.607085 gN 0.23, Sat Mar  2 13:13:34 2019
# Epcho-time 3082.89s Eval AUC 0.728701. Best AUC 0.728701.
  epoch 0 step 3000 lr 0.001 logloss 0.602565 gN 0.21, Sat Mar  2 13:40:04 2019
# Epcho-time 4673.33s Eval AUC 0.731904. Best AUC 0.731904.
  epoch 0 step 4000 lr 0.001 logloss 0.599883 gN 0.20, Sat Mar  2 14:06:29 2019
# Epcho-time 6258.55s Eval AUC 0.734174. Best AUC 0.734174.
  epoch 0 step 5000 lr 0.001 logloss 0.598001 gN 0.19, Sat Mar  2 14:32:57 2019
# Epcho-time 7846.34s Eval AUC 0.736789. Best AUC 0.736789.
  epoch 0 step 6000 lr 0.001 logloss 0.597299 gN 0.19, Sat Mar  2 14:59:27 2019
# Epcho-time 9436.22s Eval AUC 0.737986. Best AUC 0.737986.
# Epcho-time 10984.76s Eval AUC 0.737888. Best AUC 0.737986.
# Epcho-time 11090.23s Eval AUC 0.737983. Best AUC 0.737986.
Training Done! Inference...
Fold 3
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.620771 gN 0.28, Sat Mar  2 18:26:26 2019
# Epcho-time 1511.88s Eval AUC 0.721950. Best AUC 0.721950.
  epoch 0 step 2000 lr 0.001 logloss 0.606861 gN 0.22, Sat Mar  2 18:53:07 2019
# Epcho-time 3112.33s Eval AUC 0.730150. Best AUC 0.730150.
  epoch 0 step 3000 lr 0.001 logloss 0.602452 gN 0.21, Sat Mar  2 19:19:46 2019
# Epcho-time 4711.07s Eval AUC 0.733548. Best AUC 0.733548.
  epoch 0 step 4000 lr 0.001 logloss 0.600231 gN 0.20, Sat Mar  2 19:46:25 2019
# Epcho-time 6310.06s Eval AUC 0.735880. Best AUC 0.735880.
  epoch 0 step 5000 lr 0.001 logloss 0.598284 gN 0.19, Sat Mar  2 20:13:06 2019
# Epcho-time 7911.94s Eval AUC 0.737280. Best AUC 0.737280.
  epoch 0 step 6000 lr 0.001 logloss 0.597369 gN 0.18, Sat Mar  2 20:39:47 2019
# Epcho-time 9512.28s Eval AUC 0.739112. Best AUC 0.739112.
# Epcho-time 11069.96s Eval AUC 0.739138. Best AUC 0.739138.
# Epcho-time 11175.99s Eval AUC 0.739142. Best AUC 0.739142.
Training Done! Inference...
Fold 4
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.620068 gN 0.27, Sun Mar  3 00:04:29 2019
# Epcho-time 1516.60s Eval AUC 0.720749. Best AUC 0.720749.
  epoch 0 step 2000 lr 0.001 logloss 0.606028 gN 0.22, Sun Mar  3 00:31:05 2019
# Epcho-time 3113.42s Eval AUC 0.727827. Best AUC 0.727827.
  epoch 0 step 3000 lr 0.001 logloss 0.602004 gN 0.21, Sun Mar  3 00:57:39 2019
# Epcho-time 4706.73s Eval AUC 0.731407. Best AUC 0.731407.
  epoch 0 step 4000 lr 0.001 logloss 0.599989 gN 0.20, Sun Mar  3 01:24:14 2019
# Epcho-time 6301.67s Eval AUC 0.733672. Best AUC 0.733672.
  epoch 0 step 5000 lr 0.001 logloss 0.598141 gN 0.19, Sun Mar  3 01:50:51 2019
# Epcho-time 7899.20s Eval AUC 0.734939. Best AUC 0.734939.
  epoch 0 step 6000 lr 0.001 logloss 0.596731 gN 0.18, Sun Mar  3 02:17:27 2019
# Epcho-time 9495.26s Eval AUC 0.736977. Best AUC 0.736977.
# Epcho-time 11047.10s Eval AUC 0.736966. Best AUC 0.736977.
# Epcho-time 11152.71s Eval AUC 0.736979. Best AUC 0.736979.
Training Done! Inference...
0    0.490619
1    0.569940
2    0.487638
3    0.369085
4    0.503986
Name: HasDetections, dtype: float32
```

