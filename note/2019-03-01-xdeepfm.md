把 hidden size 从 [128,128] 改成 [1024,128] 虽然看起来 AUC 没什么提升。

LB: 0.690

blend with lgb (0.693): 0.696

```
Loading Train and Test Data.

  activation=['relu', 'relu', 'relu']
  batch_norm_decay=0.9
  batch_size=1024
  cross_activation=identity
  cross_layer_sizes=[128, 128, 128]
  epoch=1
  feature_nums=81
  hash_ids=200000
  hidden_size=[1024, 128]
  init_method=uniform
  init_value=0.1
  k=8
  kfold=5
  learning_rate=0.001
  metric=auc
  model=xdeepfm
  norm=True
  num_display_steps=1000
  num_eval_steps=1000
  optimizer=adam
Number: 1784296
Number: 1784296
Number: 1784296
Number: 1784296
Number: 1784299
Fold 0
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.620469 gN 0.27, Thu Feb 28 00:24:11 2019
# Epcho-time 1409.70s Eval AUC 0.723327. Best AUC 0.723327.
  epoch 0 step 2000 lr 0.001 logloss 0.606102 gN 0.22, Thu Feb 28 00:49:41 2019
# Epcho-time 2939.03s Eval AUC 0.729959. Best AUC 0.729959.
  epoch 0 step 3000 lr 0.001 logloss 0.601934 gN 0.21, Thu Feb 28 01:15:13 2019
# Epcho-time 4471.32s Eval AUC 0.733764. Best AUC 0.733764.
  epoch 0 step 4000 lr 0.001 logloss 0.599687 gN 0.20, Thu Feb 28 01:40:45 2019
# Epcho-time 6003.55s Eval AUC 0.736425. Best AUC 0.736425.
  epoch 0 step 5000 lr 0.001 logloss 0.598115 gN 0.19, Thu Feb 28 02:06:20 2019
# Epcho-time 7538.77s Eval AUC 0.738044. Best AUC 0.738044.
  epoch 0 step 6000 lr 0.001 logloss 0.597292 gN 0.18, Thu Feb 28 02:31:57 2019
# Epcho-time 9075.64s Eval AUC 0.739346. Best AUC 0.739346.
# Epcho-time 10568.32s Eval AUC 0.738751. Best AUC 0.739346.
# Epcho-time 10669.39s Eval AUC 0.739342. Best AUC 0.739346.
Training Done! Inference...
Fold 1
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.621057 gN 0.28, Thu Feb 28 05:29:19 2019
# Epcho-time 1516.98s Eval AUC 0.720557. Best AUC 0.720557.
  epoch 0 step 2000 lr 0.001 logloss 0.606563 gN 0.22, Thu Feb 28 05:55:54 2019
# Epcho-time 3112.56s Eval AUC 0.727072. Best AUC 0.727072.
  epoch 0 step 3000 lr 0.001 logloss 0.602278 gN 0.21, Thu Feb 28 06:22:25 2019
# Epcho-time 4702.94s Eval AUC 0.731995. Best AUC 0.731995.
  epoch 0 step 4000 lr 0.001 logloss 0.600050 gN 0.20, Thu Feb 28 06:48:51 2019
# Epcho-time 6288.95s Eval AUC 0.734514. Best AUC 0.734514.
  epoch 0 step 5000 lr 0.001 logloss 0.598348 gN 0.19, Thu Feb 28 07:15:24 2019
# Epcho-time 7882.23s Eval AUC 0.736328. Best AUC 0.736328.
  epoch 0 step 6000 lr 0.001 logloss 0.597383 gN 0.19, Thu Feb 28 07:42:00 2019
# Epcho-time 9478.22s Eval AUC 0.738319. Best AUC 0.738319.
# Epcho-time 11031.38s Eval AUC 0.737045. Best AUC 0.738319.
# Epcho-time 11134.80s Eval AUC 0.738331. Best AUC 0.738331.
Training Done! Inference...
Fold 2
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.621480 gN 0.28, Thu Feb 28 11:06:30 2019
# Epcho-time 1525.47s Eval AUC 0.720747. Best AUC 0.720747.
  epoch 0 step 2000 lr 0.001 logloss 0.606164 gN 0.23, Thu Feb 28 11:32:39 2019
# Epcho-time 3093.87s Eval AUC 0.728767. Best AUC 0.728767.
  epoch 0 step 3000 lr 0.001 logloss 0.602348 gN 0.21, Thu Feb 28 11:58:53 2019
# Epcho-time 4668.16s Eval AUC 0.732647. Best AUC 0.732647.
  epoch 0 step 4000 lr 0.001 logloss 0.600222 gN 0.20, Thu Feb 28 12:25:05 2019
# Epcho-time 6240.19s Eval AUC 0.734365. Best AUC 0.734365.
  epoch 0 step 5000 lr 0.001 logloss 0.598459 gN 0.19, Thu Feb 28 12:51:14 2019
# Epcho-time 7809.55s Eval AUC 0.735309. Best AUC 0.735309.
  epoch 0 step 6000 lr 0.001 logloss 0.597533 gN 0.19, Thu Feb 28 13:17:29 2019
# Epcho-time 9384.40s Eval AUC 0.737451. Best AUC 0.737451.
# Epcho-time 10917.47s Eval AUC 0.736406. Best AUC 0.737451.
# Epcho-time 11022.44s Eval AUC 0.737450. Best AUC 0.737451.
Training Done! Inference...
Fold 3
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.620273 gN 0.27, Thu Feb 28 16:42:42 2019
# Epcho-time 1504.22s Eval AUC 0.722329. Best AUC 0.722329.
  epoch 0 step 2000 lr 0.001 logloss 0.605794 gN 0.22, Thu Feb 28 17:09:09 2019
# Epcho-time 3090.69s Eval AUC 0.730019. Best AUC 0.730019.
  epoch 0 step 3000 lr 0.001 logloss 0.601940 gN 0.21, Thu Feb 28 17:35:32 2019
# Epcho-time 4674.20s Eval AUC 0.732993. Best AUC 0.732993.
  epoch 0 step 4000 lr 0.001 logloss 0.600193 gN 0.20, Thu Feb 28 18:01:55 2019
# Epcho-time 6257.03s Eval AUC 0.736452. Best AUC 0.736452.
  epoch 0 step 5000 lr 0.001 logloss 0.597736 gN 0.19, Thu Feb 28 18:28:20 2019
# Epcho-time 7842.08s Eval AUC 0.736125. Best AUC 0.736452.
  epoch 0 step 6000 lr 0.001 logloss 0.597327 gN 0.18, Thu Feb 28 18:54:46 2019
# Epcho-time 9428.27s Eval AUC 0.737748. Best AUC 0.737748.
# Epcho-time 10967.25s Eval AUC 0.737443. Best AUC 0.737748.
# Epcho-time 11072.94s Eval AUC 0.737752. Best AUC 0.737752.
Training Done! Inference...
Fold 4
# Trainable variables
  emb_v1:0, (200000, 1), 
  emb_v2:0, (200000, 8), 
  Variable:0, (648, 1024), 
  norm_0/beta:0, (1024,), 
  norm_0/gamma:0, (1024,), 
  Variable_1:0, (1024, 128), 
  norm_1/beta:0, (128,), 
  norm_1/gamma:0, (128,), 
  Variable_2:0, (128, 1), 
  exfm_part/f_0:0, (1, 6561, 128), 
  exfm_part/f_1:0, (1, 5184, 128), 
  exfm_part/f_2:0, (1, 5184, 128), 
  exfm_part/w_nn_output:0, (256, 1), 
  exfm_part/b_nn_output:0, (1,), 
  epoch 0 step 1000 lr 0.001 logloss 0.621593 gN 0.28, Thu Feb 28 22:16:49 2019
# Epcho-time 1536.25s Eval AUC 0.722177. Best AUC 0.722177.
  epoch 0 step 2000 lr 0.001 logloss 0.606159 gN 0.22, Thu Feb 28 22:43:31 2019
# Epcho-time 3138.13s Eval AUC 0.729159. Best AUC 0.729159.
  epoch 0 step 3000 lr 0.001 logloss 0.602228 gN 0.21, Thu Feb 28 23:10:09 2019
# Epcho-time 4735.88s Eval AUC 0.732694. Best AUC 0.732694.
  epoch 0 step 4000 lr 0.001 logloss 0.600467 gN 0.20, Thu Feb 28 23:36:46 2019
# Epcho-time 6333.14s Eval AUC 0.735924. Best AUC 0.735924.
  epoch 0 step 5000 lr 0.001 logloss 0.597778 gN 0.19, Fri Mar  1 00:03:21 2019
# Epcho-time 7928.73s Eval AUC 0.735892. Best AUC 0.735924.
  epoch 0 step 6000 lr 0.001 logloss 0.597128 gN 0.18, Fri Mar  1 00:30:03 2019
# Epcho-time 9530.41s Eval AUC 0.737770. Best AUC 0.737770.
# Epcho-time 11082.46s Eval AUC 0.738331. Best AUC 0.738331.
# Epcho-time 11188.63s Eval AUC 0.738337. Best AUC 0.738337.
Training Done! Inference...
0    0.528304
1    0.572800
2    0.571583
3    0.288287
4    0.461227
Name: HasDetections, dtype: float32
```

