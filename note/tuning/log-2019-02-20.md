 k = 8 时的 FM，感觉这个效果确实比 xdeepfm 差很多。

LB: 0.672 可以直接弃疗了。

```
Fold 0
/home/songzy/.virtualenvs/venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large
amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
# Trainable variables
  emb_v1:0, (200000, 1),
  emb_v2:0, (200000, 8),
  epoch 0 step 1000 lr 0.001 logloss 0.629560 gN 0.24, Tue Feb 19 22:09:47 2019
# Epcho-time 530.25s Eval AUC 0.711595. Best AUC 0.711595.
  epoch 0 step 2000 lr 0.001 logloss 0.615858 gN 0.22, Tue Feb 19 22:19:28 2019
# Epcho-time 1111.80s Eval AUC 0.716695. Best AUC 0.716695.
  epoch 0 step 3000 lr 0.001 logloss 0.612919 gN 0.22, Tue Feb 19 22:29:29 2019
# Epcho-time 1712.70s Eval AUC 0.719982. Best AUC 0.719982.
  epoch 0 step 4000 lr 0.001 logloss 0.610112 gN 0.22, Tue Feb 19 22:39:32 2019
# Epcho-time 2315.63s Eval AUC 0.722019. Best AUC 0.722019.
  epoch 0 step 5000 lr 0.001 logloss 0.609345 gN 0.22, Tue Feb 19 22:49:34 2019
# Epcho-time 2917.53s Eval AUC 0.723237. Best AUC 0.723237.
  epoch 0 step 6000 lr 0.001 logloss 0.608403 gN 0.22, Tue Feb 19 22:59:20 2019
# Epcho-time 3503.67s Eval AUC 0.723775. Best AUC 0.723775.
# Epcho-time 3998.93s Eval AUC 0.725600. Best AUC 0.725600.
# Epcho-time 4047.13s Eval AUC 0.725600. Best AUC 0.725600.
Training Done! Inference...
Fold 1
# Trainable variables
  emb_v1:0, (200000, 1),
  emb_v2:0, (200000, 8),
  epoch 0 step 1000 lr 0.001 logloss 0.630153 gN 0.25, Tue Feb 19 23:53:40 2019
# Epcho-time 558.05s Eval AUC 0.711184. Best AUC 0.711184.
  epoch 0 step 2000 lr 0.001 logloss 0.615448 gN 0.23, Wed Feb 20 00:03:46 2019
# Epcho-time 1164.73s Eval AUC 0.714712. Best AUC 0.714712.
  epoch 0 step 3000 lr 0.001 logloss 0.612880 gN 0.22, Wed Feb 20 00:13:52 2019
# Epcho-time 1770.38s Eval AUC 0.718571. Best AUC 0.718571.
  epoch 0 step 4000 lr 0.001 logloss 0.610092 gN 0.22, Wed Feb 20 00:23:40 2019
# Epcho-time 2358.05s Eval AUC 0.720586. Best AUC 0.720586.
  epoch 0 step 5000 lr 0.001 logloss 0.609435 gN 0.22, Wed Feb 20 00:33:26 2019
# Epcho-time 2943.98s Eval AUC 0.721763. Best AUC 0.721763.
  epoch 0 step 6000 lr 0.001 logloss 0.608402 gN 0.22, Wed Feb 20 00:43:15 2019
# Epcho-time 3533.55s Eval AUC 0.722900. Best AUC 0.722900.
# Epcho-time 4027.87s Eval AUC 0.723774. Best AUC 0.723774.
# Epcho-time 4074.75s Eval AUC 0.723774. Best AUC 0.723774.
Training Done! Inference...
Fold 2
# Trainable variables
  emb_v1:0, (200000, 1),
  emb_v2:0, (200000, 8),
  epoch 0 step 1000 lr 0.001 logloss 0.632257 gN 0.25, Wed Feb 20 01:38:39 2019
# Epcho-time 540.11s Eval AUC 0.710761. Best AUC 0.710761.
  epoch 0 step 2000 lr 0.001 logloss 0.616357 gN 0.23, Wed Feb 20 01:48:34 2019
# Epcho-time 1135.72s Eval AUC 0.717227. Best AUC 0.717227.
  epoch 0 step 3000 lr 0.001 logloss 0.612420 gN 0.22, Wed Feb 20 01:58:36 2019
# Epcho-time 1737.09s Eval AUC 0.718970. Best AUC 0.718970.
  epoch 0 step 4000 lr 0.001 logloss 0.610171 gN 0.22, Wed Feb 20 02:08:43 2019
# Epcho-time 2344.31s Eval AUC 0.722212. Best AUC 0.722212.
  epoch 0 step 5000 lr 0.001 logloss 0.609298 gN 0.22, Wed Feb 20 02:18:48 2019
# Epcho-time 2949.87s Eval AUC 0.723253. Best AUC 0.723253.
  epoch 0 step 6000 lr 0.001 logloss 0.608470 gN 0.22, Wed Feb 20 02:28:54 2019
# Epcho-time 3555.53s Eval AUC 0.724706. Best AUC 0.724706.
# Epcho-time 4071.44s Eval AUC 0.724422. Best AUC 0.724706.
# Epcho-time 4121.89s Eval AUC 0.724706. Best AUC 0.724706.
Training Done! Inference...
Fold 3
# Trainable variables
  emb_v1:0, (200000, 1),
  emb_v2:0, (200000, 8),
  epoch 0 step 1000 lr 0.001 logloss 0.632906 gN 0.26, Wed Feb 20 03:25:10 2019
# Epcho-time 560.13s Eval AUC 0.710931. Best AUC 0.710931.
  epoch 0 step 2000 lr 0.001 logloss 0.615932 gN 0.23, Wed Feb 20 03:35:16 2019
# Epcho-time 1166.62s Eval AUC 0.717471. Best AUC 0.717471.
  epoch 0 step 3000 lr 0.001 logloss 0.612328 gN 0.22, Wed Feb 20 03:45:24 2019
# Epcho-time 1774.59s Eval AUC 0.720014. Best AUC 0.720014.
  epoch 0 step 4000 lr 0.001 logloss 0.610646 gN 0.22, Wed Feb 20 03:55:30 2019
# Epcho-time 2380.60s Eval AUC 0.722595. Best AUC 0.722595.
  epoch 0 step 5000 lr 0.001 logloss 0.609749 gN 0.22, Wed Feb 20 04:05:36 2019
# Epcho-time 2986.49s Eval AUC 0.723305. Best AUC 0.723305.
  epoch 0 step 6000 lr 0.001 logloss 0.608410 gN 0.22, Wed Feb 20 04:15:48 2019
# Epcho-time 3598.34s Eval AUC 0.724783. Best AUC 0.724783.
# Epcho-time 4111.28s Eval AUC 0.725292. Best AUC 0.725292.
# Epcho-time 4161.72s Eval AUC 0.725292. Best AUC 0.725292.
Training Done! Inference...
Fold 4
# Trainable variables
  emb_v1:0, (200000, 1),
  emb_v2:0, (200000, 8),
  epoch 0 step 1000 lr 0.001 logloss 0.631635 gN 0.24, Wed Feb 20 05:13:30 2019
# Epcho-time 564.84s Eval AUC 0.710169. Best AUC 0.710169.
  epoch 0 step 2000 lr 0.001 logloss 0.615863 gN 0.22, Wed Feb 20 05:23:38 2019
# Epcho-time 1173.13s Eval AUC 0.716263. Best AUC 0.716263.
  epoch 0 step 3000 lr 0.001 logloss 0.612330 gN 0.22, Wed Feb 20 05:33:43 2019
# Epcho-time 1778.12s Eval AUC 0.718955. Best AUC 0.718955.
  epoch 0 step 4000 lr 0.001 logloss 0.610657 gN 0.22, Wed Feb 20 05:43:50 2019
# Epcho-time 2384.74s Eval AUC 0.720825. Best AUC 0.720825.
  epoch 0 step 5000 lr 0.001 logloss 0.609743 gN 0.22, Wed Feb 20 05:54:00 2019
# Epcho-time 2994.79s Eval AUC 0.721058. Best AUC 0.721058.
  epoch 0 step 6000 lr 0.001 logloss 0.607701 gN 0.22, Wed Feb 20 06:04:08 2019
# Epcho-time 3603.06s Eval AUC 0.723076. Best AUC 0.723076.
# Epcho-time 4120.30s Eval AUC 0.723903. Best AUC 0.723903.
# Epcho-time 4168.65s Eval AUC 0.723903. Best AUC 0.723903.
Training Done! Inference...
0    0.492490
1    0.626055
2    0.502936
3    0.321572
4    0.513891
Name: HasDetections, dtype: float32
```

